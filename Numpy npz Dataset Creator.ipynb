{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7cd6ebc-cac0-460e-a22c-fc260a5ebb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed677eb7-8c39-4960-91bd-e6d9fa84073d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c26524bf-09a5-4166-9825-ba6f45c78a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d26522-5935-49ae-b416-b10c9f2db5a4",
   "metadata": {},
   "source": [
    "# Include image processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da251fbf-b82f-4f6a-9eb9-04f36bae11c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_pipeline_with_resize(folder_path,height,width):\n",
    "    images_data = []\n",
    "    labels = []\n",
    "    size_=(width,height)\n",
    "    Classes = os.listdir(folder_path)\n",
    "\n",
    "    for i in range(len(Classes)):\n",
    "        new_path = folder_path + '/' + Classes[i]\n",
    "        Classes2 = os.listdir(new_path)\n",
    "\n",
    "        for j in range(len(Classes2)):\n",
    "            \n",
    "\n",
    "            image_path = folder_path + '/' + Classes[i] + '/' + Classes2[j]\n",
    "            \n",
    "            try:\n",
    "                # Attempt to open the image\n",
    "                image = Image.open(image_path)\n",
    "\n",
    "                # Resize the images\n",
    "                img_resized = image.resize(size_, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Convert the image to a NumPy array\n",
    "                image_array = np.array(img_resized)\n",
    "                \n",
    "                # Append the image array to the list\n",
    "                images_data.append(image_array)\n",
    "                \n",
    "                labels.append(Classes[i])\n",
    "            \n",
    "            except (IOError, OSError) as e:\n",
    "                # Handle the exception (e.g., print a warning, skip the image, etc.)\n",
    "                print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "    return images_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4fbefec5-6faf-44ee-b94c-94983d7a5c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_to_grayscale(image_array):\n",
    "    length= len(image_array)\n",
    "    images_list=[]\n",
    "    for i in range(length):\n",
    "        # Compute the weighted sum to convert to grayscale\n",
    "        images_list.append(np.dot(image_array[i], [0.299, 0.587, 0.114]))\n",
    "\n",
    "    return images_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100c8495-9e0a-49e3-a21d-1da4617bf389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Image_scalling(data_list):\n",
    "    list_length=len(data_list)\n",
    "    new_data_list=[]\n",
    "    for i in range(list_length):\n",
    "        new_data_list.append((data_list[i]/255))\n",
    "\n",
    "    return new_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56550213-7f02-4774-bc99-683183a72c42",
   "metadata": {},
   "source": [
    "# Function to Change Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf9059-c108-4e75-877c-570b4c584cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def convert_labels(labels):\n",
    "    # Create a copy of the labels array to avoid modifying the original array\n",
    "    labels=np.array(labels)\n",
    "    converted_labels = labels.copy()\n",
    "    \n",
    "    # Convert 'cat' to 1 and 'dog' to 0\n",
    "    converted_labels[labels == 'cat'] = 1\n",
    "    converted_labels[labels == 'dog'] = 0\n",
    "    \n",
    "    return converted_labels  # Convert labels to integers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d25cee-d922-4b0f-b39a-ebb834fffc1f",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a16488c1-9e7c-46f0-b9b4-7cf2fd67a24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dog_cat'\n",
    "test_dir ='test_dog_cat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf81490-0aca-45d9-8eb4-7ca47bc660a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,ytrain=image_pipeline_with_resize(dataset_dir,200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e5a05b4d-d314-47fe-a4f2-f0479d1ccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest,ytest=image_pipeline_with_resize(test_dir,200,200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4b9ec1-4e90-4a30-aab4-ecaa3a4a64c1",
   "metadata": {},
   "source": [
    "# Create numpy 'npz' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "463b3366-c1a9-49b6-932d-b2b066d05d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=np.array(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83115491-3045-403d-b324-dde3410ec9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=np.array(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81a5cc7f-ec79-451c-8e7b-40b3081c10fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain=np.array(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcbe51e-e19a-4dbe-a137-1ee9b67ec84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytrain=np.array(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7400585-2501-42b8-8655-127b0a758891",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('dog_cat_dataset.npz',x_train=xtrain,y_train=ytrain,x_test=xtest,y_test=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1165dbf2-c881-4757-8d6d-a34cc8c6e5da",
   "metadata": {},
   "source": [
    "# Load numpy 'npz' dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905c57a0-04f9-4242-bf5b-d3dae72f1971",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('dog_cat_dataset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0444cf46-edde-4a4e-9047-2baa2b32a458",
   "metadata": {},
   "outputs": [],
   "source": [
    "images11=data['x_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39d1ac2a-8352-4948-80b8-10f138d4c326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 59  81 104]\n",
      "  [ 55  76 100]\n",
      "  [ 54  73  97]\n",
      "  ...\n",
      "  [126 104  66]\n",
      "  [126 104  65]\n",
      "  [128 103  63]]\n",
      "\n",
      " [[ 61  83 106]\n",
      "  [ 58  79 103]\n",
      "  [ 56  75  99]\n",
      "  ...\n",
      "  [125 103  65]\n",
      "  [124 102  62]\n",
      "  [127 102  61]]\n",
      "\n",
      " [[ 57  79 102]\n",
      "  [ 60  80 104]\n",
      "  [ 59  79 103]\n",
      "  ...\n",
      "  [126 104  64]\n",
      "  [126 103  62]\n",
      "  [131 105  64]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 78  70  62]\n",
      "  [ 83  74  67]\n",
      "  [ 82  72  65]\n",
      "  ...\n",
      "  [171 142 102]\n",
      "  [164 136  96]\n",
      "  [156 126  88]]\n",
      "\n",
      " [[ 81  73  65]\n",
      "  [ 84  75  68]\n",
      "  [ 84  74  67]\n",
      "  ...\n",
      "  [170 141 101]\n",
      "  [169 139 100]\n",
      "  [165 135  97]]\n",
      "\n",
      " [[ 78  70  63]\n",
      "  [ 83  74  67]\n",
      "  [ 85  75  69]\n",
      "  ...\n",
      "  [169 140 100]\n",
      "  [168 138 100]\n",
      "  [165 135  97]]]\n"
     ]
    }
   ],
   "source": [
    "print(images11[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777f1f6d-8a06-4992-bb79-4b9111b4dc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eabf7ccd-9e66-4202-a7dd-bfb630b53a47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74474772-5d55-43ab-b356-35a74e642182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "tensorflow_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
